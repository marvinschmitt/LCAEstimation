{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../BayesFlow')))\n",
    "\n",
    "from bayesflow.trainers import MetaTrainer, ParameterEstimationTrainer\n",
    "from bayesflow.networks import SequenceNet, EvidentialNetwork, InvertibleNetwork, InvariantNetwork\n",
    "from bayesflow.amortizers import MetaAmortizer, SingleModelAmortizer\n",
    "from bayesflow.models import GenerativeModel\n",
    "from bayesflow.diagnostics import true_vs_estimated\n",
    "\n",
    "from generative_models import batch_generate_levy_lca, generate_levy_lca\n",
    "\n",
    "from meta_aux_classes import *\n",
    "\n",
    "%load_ext Cython\n",
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prior(batch_size, n_models, p_vals=None):\n",
    "    \"\"\"\n",
    "    Samples from the models' prior batch size times and converts to one-hot.\n",
    "    Assumes equal model priors.\n",
    "    ----------\n",
    "    \n",
    "    Arguments:\n",
    "    batch_size : int  -- the number of samples to draw from the prior\n",
    "    ----------\n",
    "    \n",
    "    Returns:\n",
    "    m_true : np.ndarray of shape (batch_size, theta_dim) -- the samples batch of parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Equal priors, if nothign specified\n",
    "    if p_vals is None:\n",
    "        p_vals = [1/n_models] * n_models\n",
    "    m_idx = np.random.choice(n_models, size=batch_size, p=p_vals).astype(np.int32)\n",
    "    return m_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LCAPrior:\n",
    "    def __init__(self, n_conditions=2, n_accumulators=2):\n",
    "        self.n_conditions = n_conditions\n",
    "        self.n_accumulators = n_accumulators\n",
    "    \n",
    "    def __call__(self, batch_size):\n",
    "        p = np.random.uniform(0.10, 2.00, size=(batch_size, self.n_conditions * self.n_accumulators)).astype('double')\n",
    "        a = np.random.uniform(0.05, 0.80, size=batch_size).astype('double')\n",
    "        beta = np.random.uniform(0.01, 0.99, size=batch_size).astype('double')\n",
    "        kappa = np.random.uniform(0.01, 0.99, size=batch_size).astype('double')\n",
    "        ndt = np.random.uniform(0.1, 0.4, size=batch_size).astype('double')\n",
    "        # alpha = np.random.uniform(1.0, 2.0, size=batch_size).astype('double')\n",
    "        \n",
    "        params = np.column_stack((p, a, beta, kappa, ndt))\n",
    "        return params\n",
    "    \n",
    "\n",
    "class LCASimulator:\n",
    "    def __init__(self, n_conditions=2, n_accumulators=2):\n",
    "        self.n_conditions = n_conditions\n",
    "        self.n_accumulators = n_accumulators\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(n, c):\n",
    "        \"\"\"Partitions the integer n into c equally sized chunks and returns an c-lengthed array of chunk sizes.\"\"\"\n",
    "        return [n // c + (1 if x < n % c else 0)\n",
    "                      for x in range (c)]\n",
    "        \n",
    "    def __call__(self, params, n_obs):\n",
    "        n_sim = params.shape[0]\n",
    "        \n",
    "        # total number of drift rates = n_cond * n_acc\n",
    "        n_p = self.n_conditions * self.n_accumulators\n",
    "        \n",
    "        # Split n_obs equally between conditions \n",
    "        n_obs_cond = self.partition(n_obs, self.n_conditions)\n",
    "\n",
    "        # Shared parameters\n",
    "        a, beta, kappa, ndt = tuple(params.T[n_p:])\n",
    "        alpha = np.full_like(a, 2.0, dtype='double')   # Levy alpha-stable parameter\n",
    "        \n",
    "        # Individual parameters per cond and accumulator: p, x_acc\n",
    "        p_cond = params[:, :n_p].reshape((n_sim, self.n_accumulators, self.n_conditions))\n",
    "        x_acc = np.zeros_like(p_cond, dtype='double')\n",
    "        \n",
    "        # initialize sim_data array\n",
    "        sim_data = np.empty((n_sim, n_obs), dtype=np.float32)\n",
    "        \n",
    "        # indexing along n_obs dimension\n",
    "        start_idx = end_idx = 0\n",
    "        for c in range(self.n_conditions):\n",
    "            start_idx, end_idx = end_idx, end_idx + n_obs_cond[c]  # increment by current n_obs_cond\n",
    "            cond_data = batch_generate_levy_lca(n_obs_cond[c], \n",
    "                                                p_cond[:, :, c], x_acc[:, :, c],  # individual \n",
    "                                                kappa, beta, a, ndt, alpha)       # shared\n",
    "            sim_data[:, start_idx:end_idx] = np.array(cond_data, dtype=np.float32)\n",
    "        \n",
    "        cond_row = np.concatenate([n_obs_cond[c] * [c] for c in range(self.n_conditions)])\n",
    "        cond_arr = np.stack(n_sim * [cond_row])\n",
    "        sim_data = np.stack((sim_data, cond_arr), axis=-1)\n",
    "        \n",
    "        return sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.63436814 0.54493887 1.96567173 0.19449826 0.23269452 0.98280085\n",
      "  0.43122805 0.39303889]\n",
      " [1.23874067 1.05948886 0.47280855 0.77688269 0.63313364 0.80720777\n",
      "  0.23222514 0.27481739]\n",
      " [1.94853453 0.45842388 0.60293779 0.92154032 0.08411581 0.76959913\n",
      "  0.68616878 0.10634428]]\n",
      "[[[ 0.41103888  0.        ]\n",
      "  [ 0.42403889  0.        ]\n",
      "  [-0.42903888  0.        ]\n",
      "  [ 0.45603889  0.        ]\n",
      "  [-0.40503889  0.        ]\n",
      "  [ 0.60703892  1.        ]\n",
      "  [-0.40803888  1.        ]\n",
      "  [-0.41303888  1.        ]\n",
      "  [-0.41003889  1.        ]\n",
      "  [ 0.41203889  1.        ]]\n",
      "\n",
      " [[ 0.70781738  0.        ]\n",
      "  [ 0.51881737  0.        ]\n",
      "  [-0.39481738  0.        ]\n",
      "  [-0.37081739  0.        ]\n",
      "  [ 0.53681737  0.        ]\n",
      "  [-0.44581738  1.        ]\n",
      "  [ 0.39981738  1.        ]\n",
      "  [-0.4258174   1.        ]\n",
      "  [ 0.68181741  1.        ]\n",
      "  [ 0.55881739  1.        ]]\n",
      "\n",
      " [[ 0.11234428  0.        ]\n",
      "  [-0.11834428  0.        ]\n",
      "  [ 0.13234428  0.        ]\n",
      "  [-0.10934428  0.        ]\n",
      "  [-0.11434428  0.        ]\n",
      "  [-0.10934428  1.        ]\n",
      "  [ 0.12034428  1.        ]\n",
      "  [-0.11234428  1.        ]\n",
      "  [-0.11634428  1.        ]\n",
      "  [-0.12734428  1.        ]]]\n",
      "(6, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "# levy_lca_simulator() debugger\n",
    "prior = LCAPrior(n_conditions=2, n_accumulators=2)\n",
    "simulator = LCASimulator(n_conditions=2, n_accumulators=2)\n",
    "p = prior(6)\n",
    "x = simulator(p, 10)\n",
    "print(p[[0, 2,4]])\n",
    "print(x[[0, 2,4]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-25 19:22:19.776628: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-05-25 19:22:19.776905: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "D = 8 # \n",
    "\n",
    "summary_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 2,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    2,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 128},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 128},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 128},\n",
    "}\n",
    "\n",
    "summary_net = InvariantNetwork(summary_meta)  # Output size 128\n",
    "\n",
    "\n",
    "inference_meta = {\n",
    "    'n_coupling_layers': 4,\n",
    "    's_args': {\n",
    "        'units': [64, 64, 64],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [64, 64, 64],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'n_params': D,\n",
    "    'alpha': 1.9,\n",
    "    'permute': True\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork({'n_params': D})\n",
    "\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model = GenerativeModel(prior=prior, simulator=simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8) (32, 250, 2)\n"
     ]
    }
   ],
   "source": [
    "p, x = generative_model(32, 250)\n",
    "print(p.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ParameterEstimationTrainer(amortizer,\n",
    "                      generative_model,\n",
    "                      learning_rate=0.0001,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainer.train_online(epochs=2, iterations_per_epoch=100, batch_size=16,\n",
    "                                            n_obs=np.random.randint(100, 201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainer.train_rounds(epochs=2, rounds=2, sim_per_round=100, batch_size=32, \n",
    "                              n_obs=np.random.randint(100, 501))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate (quick and dirty)\n",
    "p, x = trainer._forward_inference(100, 100)\n",
    "param_samples = trainer.network.sample(x, n_samples=1000)\n",
    "param_means = param_samples.mean(axis=0)\n",
    "true_vs_estimated(p, param_means, ['p11', 'p12', 'p21', 'p22', 'a', 'beta', 'kappa', 'ndt'], figsize=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
